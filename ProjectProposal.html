<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html><head></head><body>


  

  
  
  




  
  

  

  

  
  
  
  
  
  
  
  
  
  
  

  








  
        
    <hgroup class="auto-fadein">
      <h1></h1>
      
      <p></p>
            <p style="margin-top: 6px;margin-left: -2px;">22/03/2022</p>
          </hgroup>
  

<hgroup><h2>DATA :</h2></hgroup><article>

<p>-Our data source is <strong>Reddit API</strong>. We are planning to utilize RedditExtractoR “<a rel="noopener" href="https://cran.r-project.org/web/packages/RedditExtractoR/" title="">https://cran.r-project.org/web/packages/RedditExtractoR/</a>”.</p>

<p>-This API returns contents of all of Reddit ecosystem, subreddits, user data and Karma, upvotes and downvotes, trending posts.</p>

<p>-We intend to use the API data in JSON format. We plan to analyze a few subreddits and the comments posted on them, to classify the types of users.</p>

</article><hgroup><h2>PROBLEM DESCRIPTION :</h2></hgroup><article>

<p>Reddit.com is a social media news and discussion forum, interesting data can be pulled from Reddit that can show real-time trends of popular topics.</p>

<p>-There are thousands of users on the platform, commenting on different topics and forum, expressing their views. As a mass media platform, it can be weaponized into a powerful tool that can manipulate the masses.</p>

<p>-As part of our project, we will be classifying accounts as either normal users or bots on Reddit.</p>

</article><hgroup><h2>ANALYTICS PLAN:</h2></hgroup><article>

<p>-For cleaning the data, we will be making use of tidyverse package to remove outliers and ensure data is tidy before analysis.</p>

<p>-The text of each comment will be referred to as a document and each comment will also have a corresponding label, i.e.&#160;normal or bot. we intend to convert each comment into a bag of words and represent each comment as a vector.</p>

<p>-We plan to make use of different classification models to predict whether each comment is a bot, a troll, or a normal user</p>

</article><hgroup><h2>EVALUATION PLAN:</h2></hgroup><article>

<p>We plan to compare models above and find the best model among them. To evaluate the quality of the output, we use RMSE, confusion matrix, prediction, recall and F scores.</p></article>


  











<script type="module" src="https://s.brightspace.com/lib/bsi/20.22.6-230/unbundled/mathjax.js"></script><script type="text/javascript">document.addEventListener('DOMContentLoaded', function() {
					if (document.querySelector('math') || /\$\$|\\\(|\\\[|\\begin{|\\ref{|\\eqref{/.test(document.body.innerHTML)) {
						document.querySelectorAll('mspace[linebreak="newline"]').forEach(elm => {
							elm.setAttribute('style', 'display: block; height: 0.5rem;');
						});

						window.D2L.MathJax.loadMathJax({
							'outputScale': 1.3,
							'renderLatex': false
						});
					}
				});</script></body></html>